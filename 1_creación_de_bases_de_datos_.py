# -*- coding: utf-8 -*-
"""1. Creación de bases de datos.

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZPkBZUcvTM_yNHxpkAAMGFrbti-xN0wA

[Guia al Conjunto de Datos](https://sorry.vse.cz/~berka/challenge/pkdd1999/berka.htm)

[Extracto del Diseño](https://dbdesigner.page.link/7iRemaQAUMsbFb2o7)

Estudiante: `....`

Érase una vez un banco que ofrecía servicios particulares (gestión de cuentas, oferta de préstamos, etc).
El banco quiere mejorar sus servicios encontrando grupos interesantes de clientes (diferenciar entre clientes buenos y malos). Los directores del banco solo tienen una pequeña idea de quién es un buen cliente y quien es un mal cliente.
Afortunadamente, el banco almacena todos los datos de sus clientes, las cuentas, préstamos concedidos, tarjetas de crédito, etc. Por tanto, los directores del banco esperan encontrar algunas respuestas analizando estos datos.

# Creación de la Base de Datos

Importamos las librerías Python que vamos a utilizar para acceder a las bases
de datos.
"""

import pandas as pd #Librería muy popular especializada en el manejo y análisis de estructura de datos.
import sqlite3 as sql #Librería para conectar con sql.
import codecs #Codificadores y decodificadores para convertir textos entre diferentes representaciones.

"""
Vamos a crear nuestra base de datos. 

SQLite se maneja a nivel de fichero, si este no exite entonces de crea. En Colab siempre de forma no permanente. 

Para manejar este fichero manejaremos el objeto de **conexión** a la base de datos.  

>Una **conexión** a base de datos es la forma que un servidor de base de datos y su software cliente se comunican entre sí. 

>El cliente utiliza una conexión a base de datos para enviar comando y recibir respuestas del servidor

"""

dbfile = "data_berka.db"

con = sql.connect(dbfile)
con

"""Lo siguiente vamos a crear una **tabla** de las que tenemos. Normalmente crearemos aquella que no contiene claves ajenas como district. 

Para ello con la sentencia CREATE identificamos los atributos que va a tener la tabla.

```
CREATE TABLE <nombre_tabla> (
  <nombre_campo> <tipo campo> <primary key, not null, etc.>,
  ...
  FOREIGN KEY (<nombre_campo_fk) 
     REFERENCES <nombre_tabla_referencia> (<nombre_pk_tabla_referencia>)
)
```
Los tipos de datos que se manejan en SQLite se pueden consultar en [SQLite Data Types](https://www.sqlite.org/datatype3.html)

Cargamos los datos de nuestra fuente de datos

Se trata de la tabla más pesada, muchas tablas hacen referencia a ella pero ella no hace referencia a ninguna (tabla madre).
"""

!wget https://raw.githubusercontent.com/zhouxu-ds/loan-default-prediction/main/data/district.asc

"""## Cargar tabla district





Para crear la tabla ejecutaremos execute



"""

con.execute('CREATE TABLE DISTRICT (A1 INT PRIMARY KEY, A2 TEXT, A3 TEXT, A4 INT,A5 INT, A6 INT,' + 
  'A7 INT, A8 INT, A9 INT, A10 REAL, A11 INT, A12 REAL, A13 REAL, A14 INT, A15 INT, A16 INT)')
#Creamos la tabla con la sentencia CREATE, debemos crear la clave primaria y tener en cuenta el tipo de dato.
#Es IMPORTANTE identificar bien los textos. Esta será la tabla más larga.
#Para crear la tabla ejecutamos el comando y la sentencia CREATE correspondiente.

"""
Finalmente "guardaremos los cambios" con **commit**

> Una sentencia **COMMIT** en SQL finaliza una transacción de base de datos dentro de un sistema gestor de base de datos relacional (RDBMS) y hace visibles todos los cambios a otros usuario"""

con.commit()

"""Cualquier ejecución de una sentencia SQL sobre la base de datos nos crea un cursor el cual utilizaremos sobre todo para las consultas 

> Cursor se refiere a una estructura de control utilizada para el recorrido (y potencial procesamiento) de los registros del resultado de una consulta.
"""

cursor = con.execute("SELECT name FROM sqlite_master WHERE type='table';")
tables = [
     v[0] for v in cursor.fetchall()
     if v[0] != "sqlite_sequence"
]
cursor.close()
tables

"""3. Cargamos los datos de la tabla

En este caso lo vamos a hacer mediante la utilización de una librería de Python como es PANDAS.

- En la primera parte tenemos "leer el CSV" y que el separador es ";".

- En la segunda parte le decimos a la base de datos dónde va dirigido (la tabla district con la conexión que nos dice que es base de datos donde va la conexión que no existe pero si existe la añade).
"""

pd.read_csv('district.asc', sep = ";" ).to_sql('DISTRICT', con, if_exists='append', index = False)

"""4. Vamos a consultar los datos que tiene esta tabla que acabamos de cargar (es una sentencia de comprobación)."""

pd.read_sql_query("SELECT * FROM DISTRICT", con)

"""## Cargar resto de tablas

### account

Ahora debemos obtener el fichero de datos (el nombre del fichero es el de la tabla más asc).
"""

!wget https://raw.githubusercontent.com/zhouxu-ds/loan-default-prediction/main/data/account.asc

"""- Crear tabla con el nombre "Account". Los id son números enteros, el date es tipo cadena de caracteres (NO FECHA). 
- Cada secuencia está separada por comas y la clave ajena es sobre district (campo azul) y hay que especificarlo también (referencia a la tabla district con su campo que es A1). 
"""

con.execute('CREATE TABLE IF NOT EXISTS ACCOUNT (account_id INT PRIMARY KEY, district_id INT, frequency TEXT, date INT, '
      + 'FOREIGN KEY (district_id) REFERENCES district (A1))')
con.commit()

"""Cargamos los datos en la tabla con el mismo procedimiento que antes:"""

pd.read_csv('account.asc', sep = ";" ).to_sql('ACCOUNT', con, if_exists='append', index = False)

"""Introducimos la sentencia de comprobación.
- LIMIT 10 para visualizar la tabla con los diez primeros casos.
"""

pd.read_sql_query("SELECT * FROM ACCOUNT LIMIT 10", con)

"""#### Manipulamos estos datos

Vamos a utilizar la sentencia UPDATE para traducir del checo al inglés
"""

con.execute("UPDATE ACCOUNT SET frequency = 'monthly' WHERE frequency = 'POPLATEK MESICNE'")
con.execute("UPDATE ACCOUNT SET frequency = 'weekly' WHERE frequency = 'POPLATEK TYDNE'")
con.execute("UPDATE ACCOUNT SET frequency = 'after_tr' WHERE frequency = 'POPLATEK PO OBRATU'")
con.commit()

pd.read_sql_query("SELECT * FROM ACCOUNT LIMIT 10", con)

"""### client

1. Descarga de los datos
"""

!wget https://raw.githubusercontent.com/zhouxu-ds/loan-default-prediction/main/data/client.asc

"""2. Creación de la tabla"""

con.execute("CREATE TABLE IF NOT EXISTS CLIENT (client_id INT PRIMARY KEY,birth_number varchar,	district_id INT, "
            + "FOREIGN KEY (district_id) REFERENCES district (A1))");
con.commit()

"""3. Carga de los datos a la tabla"""

pd.read_csv('client.asc', sep = ";" ).to_sql('CLIENT', con, if_exists='append', index = False)

"""4. Comprobar que la creación y la carga se ha hecho bien"""

pd.read_sql_query("SELECT * FROM CLIENT LIMIT 10", con)

"""5. Código para borrado después de un diseño incorrecto"""

con.execute("DROP TABLE CLIENT");
con.commit()

"""### disposition

1. Descargamos los datos (igual que en los casos anteriores).
"""

!wget https://raw.githubusercontent.com/zhouxu-ds/loan-default-prediction/main/data/disp.asc

"""2. Creamos la tabla."""

con.execute("CREATE TABLE IF NOT EXISTS  DISPOSITION (disp_id integer PRIMARY KEY, client_id integer,	account_id integer,	type varchar, "
      "FOREIGN KEY (client_id) REFERENCES client (client_id), " + 
      "FOREIGN KEY (account_id) REFERENCES account (account_id))")

con.commit()

"""3. Carga de los datos en la tabla."""

pd.read_csv('disp.asc', sep = ";" ).to_sql('DISPOSITION', con, if_exists='append', index = False)

"""4. Sentencia de comprobación de la tabla (con el límite de las 10 primeras observaciones)."""

pd.read_sql_query("SELECT * FROM DISPOSITION LIMIT 10", con)

"""### loan

1. Descargamos los datos.
"""

!wget https://raw.githubusercontent.com/zhouxu-ds/loan-default-prediction/main/data/loan.asc

"""2. Creamos la tabla. """

con.execute("CREATE TABLE  IF NOT EXISTS LOAN (loan_id INT,account_id INT,	date INT, "
	"amount INT, duration INT, payments DECIMAL, status varchar,"
  "FOREIGN KEY (account_id) REFERENCES account (account_id))")
con.commit()

"""3. Cargamos los datos a la tabla."""

pd.read_csv('loan.asc', sep = ";" ).to_sql('LOAN', con, if_exists='append', index = False)

"""4. Introducimos la sentencia de comprobación de la tabla."""

pd.read_sql_query('SELECT * FROM LOAN LIMIT 10', con)

"""### trans

1. Cargar los datos al entorno
"""

!wget https://raw.githubusercontent.com/zhouxu-ds/loan-default-prediction/main/data/trans.asc

"""2. Ejecutar el CREATE"""

con.execute('CREATE TABLE IF NOT EXISTS  TRANS (trans_id	INT PRIMARY KEY, account_id	INT, date INT, type TEXT, operation TEXT,' + 
  'amount REAL, balance REAL, k_symbol TEXT, bank TEXT, account INT, FOREIGN KEY (account_id) REFERENCES account (account_id))')
con.commit()

"""3. Cargar los datos en la tabla"""

pd.read_csv('trans.asc', sep = ";" ).to_sql('TRANS', con, if_exists='append', index = False)

"""4. Comprobar la carga de los datos"""

pd.read_sql_query("SELECT * FROM TRANS LIMIT 10", con)

"""### credit card

1. Obtener los datos
"""

!wget https://raw.githubusercontent.com/zhouxu-ds/loan-default-prediction/main/data/card.asc

"""2. Ejecutar el CREATE"""

con.execute("CREATE TABLE CREDIT_CARD (card_id INT PRIMARY KEY,disp_id integer,	type varchar,	issued varchar,"
  + "FOREIGN KEY (disp_id) REFERENCES DISPOSITION (disp_id))");
con.commit()

"""3. Cargar los datos"""

pd.read_csv('card.asc', sep = ";" ).to_sql('CREDIT_CARD', con, if_exists='append', index = False)

"""4. Comprobar la creación y la carga

"""

pd.read_sql_query('SELECT * FROM CREDIT_CARD LIMIT 10', con)

"""### permanent order

1. Descarga de los datos
"""

!wget https://raw.githubusercontent.com/zhouxu-ds/loan-default-prediction/main/data/order.asc

"""2. Creación de la tabla

"""

con.execute("CREATE TABLE PERMANENT_ORDER (order_id INT,account_id INT,	bank_to varchar, "
	"account_to varchar, 	amount decimal,	k_symbol varchar,"
  "FOREIGN KEY (account_id) REFERENCES account (account_id))")
con.commit()

"""3. Carga de los datos a la tabla

"""

pd.read_csv('order.asc', sep = ";" ).to_sql('PERMANENT_ORDER', con, if_exists='append', index = False)

"""4. Comprobar tabla"""

pd.read_sql_query('SELECT * FROM PERMANENT_ORDER LIMIT 10', con)